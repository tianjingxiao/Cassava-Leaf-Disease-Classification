{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from project.infrastructure.model_trainer import Model\n",
    "from project.infrastructure.img_dataset import ImageDataset\n",
    "from project.infrastructure.torchsampler import ImbalancedDatasetSampler\n",
    "import project.infrastructure.utils as utils\n",
    "import project.infrastructure.pytorch_util as ptu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# not using for now\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "except ImportError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "home_dir = Path.home()\n",
    "print(f\"current_dir: {current_dir}\")\n",
    "print(f\"home_dir:{home_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config PATH"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Config data_dir, img_dir\n",
    "data_dir = Path(\"../../data/\")\n",
    "leaf_data_dir: str = \"cassava-leaf-disease-classification/\"\n",
    "csv_file_name: str = \"train.csv\"\n",
    "\n",
    "csv_file_path = data_dir/leaf_data_dir/csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_folder_name: str = \"train_images\"\n",
    "img_dir = data_dir/leaf_data_dir/img_folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Noticed that the dataset is unbalanced\n",
    "# TODO: handle class weight for imbalanced dataset\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set overflow warning to error instead\n",
    "np.seterr(all='raise')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Enable cuDNN Auto-tuner before launching training loop\n",
    "# Improve performance (For convolutional networks only!)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data into train and valid (9:1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "While I used train_test_split() to create both a training and validation dataset,\n",
    "consider exploring cross validation instead.\n",
    "'''\n",
    "# Split dataset into train and valid\n",
    "df_train, df_valid = model_selection.train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    train_size=0.9,\n",
    "    random_state=SEED,\n",
    "    stratify=df.label.values\n",
    ")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get image path for both training and validation\n",
    "# Remember to convert path object to str!!\n",
    "train_img_paths = [str(img_dir/img_id) for img_id in df_train[\"image_id\"].values]\n",
    "valid_img_paths = [str(img_dir/img_id) for img_id in df_valid[\"image_id\"].values]\n",
    "\n",
    "# Get image label for both training and validation\n",
    "train_targets = df_train.label.values\n",
    "valid_targets = df_valid.label.values\n",
    "\n",
    "# Verify img paths\n",
    "train_img_paths[:3], valid_img_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# show images\n",
    "utils.display_image_grid(\n",
    "    images_filepaths=train_img_paths[0:15],\n",
    "    predicted_labels=train_targets[0:15]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## data_transforms\n",
    "Image augmentation is a process of creating new training examples from the existing ones.\n",
    "To make a new sample, you slightly change the original image\n",
    "\n",
    "* Note that in the validation pipeline we will use A.CenterCrop instead of A.RandomCrop\n",
    "because we want our validation results to be deterministic\n",
    "(so that they will not depend upon a random location of a crop)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# p_i follows p_i = floor(1/i)\n",
    "\n",
    "p1 = 1      # compose\n",
    "p2 = 0.5    # operation\n",
    "p3 = 0.3    # one of\n",
    "p4 = 0.2    # stand alone or inside one of\n",
    "\n",
    "# Pleas go through the image dataset to view the image in order to understand what operation need to perform\n",
    "data_transforms = {\n",
    "    # Training augmentation\n",
    "    \"train_img_aug\": A.Compose(\n",
    "        [\n",
    "            # Crop and Resize\n",
    "            A.Resize(width=300, height=300),\n",
    "            A.RandomCrop(width=256, height=256),\n",
    "\n",
    "            # Affine transform\n",
    "            A.Transpose(p=p2),\n",
    "            A.HorizontalFlip(p=p2),\n",
    "            A.VerticalFlip(p=p2),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=p3),\n",
    "\n",
    "            # Add noise\n",
    "            A.OneOf([\n",
    "                A.IAAAdditiveGaussianNoise(p=0.9),\n",
    "                A.GaussNoise(p=0.6),\n",
    "            ], p=p3),\n",
    "\n",
    "            # Blur\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(p=.2),\n",
    "                A.MedianBlur(blur_limit=3, p=0.1),\n",
    "                A.Blur(blur_limit=3, p=0.1),\n",
    "            ], p=p3),\n",
    "\n",
    "            # Distortion\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(p=0.3),\n",
    "                A.GridDistortion(p=.1),\n",
    "                A.IAAPiecewiseAffine(p=0.3),\n",
    "            ], p=p3),\n",
    "\n",
    "            # Light intensity\n",
    "            A.OneOf([\n",
    "                A.CLAHE(clip_limit=2),\n",
    "                A.IAASharpen(),\n",
    "                A.IAAEmboss(),\n",
    "                A.RandomBrightnessContrast(),\n",
    "            ], p=p3),\n",
    "\n",
    "            # RGB\n",
    "            A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=p2),\n",
    "\n",
    "            # HSV color space\n",
    "            A.HueSaturationValue(p=p2),\n",
    "\n",
    "            # Normalization\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "        ], p=p1\n",
    "    ),\n",
    "\n",
    "    # Validation augmentation\n",
    "    \"valid_img_aug\": A.Compose(\n",
    "        [\n",
    "            A.Resize(width=300, height=300),\n",
    "            A.CenterCrop(width=256, height=256),\n",
    "            A.Transpose(p=p2),\n",
    "            A.HorizontalFlip(p=p2),\n",
    "            A.VerticalFlip(p=p2),\n",
    "            A.ShiftScaleRotate(p=p3),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ], p=p1\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clear gpu cache to release memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Create training and validation dataset\n",
    "train_dataset = ImageDataset(\n",
    "    image_paths=train_img_paths,\n",
    "    targets=train_targets,\n",
    "    augmentations=data_transforms[\"train_img_aug\"]\n",
    ")\n",
    "\n",
    "valid_dataset = ImageDataset(\n",
    "    image_paths=valid_img_paths,\n",
    "    targets=valid_targets,\n",
    "    augmentations=data_transforms[\"valid_img_aug\"]\n",
    ")\n",
    "\n",
    "print(train_dataset[100], '\\n')\n",
    "# print(type(train_dataset[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note dataloader is implemented inside Model.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Visualize training images after augmentation\n",
    "perm = np.random.permutation(100)[:15]\n",
    "\n",
    "train_images_array_lst = [train_dataset[int(i)]['image'] for i in perm]\n",
    "train_images_label_lst = [train_dataset[int(i)]['target'] for i in perm]\n",
    "utils.display_image_grid(\n",
    "    images_array_lst=train_images_array_lst,\n",
    "    true_labels=train_images_label_lst\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Visualize validation images after augmentation\n",
    "valid_images_array_lst = [valid_dataset[int(j)]['image'] for j in perm]\n",
    "valid_images_label_lst = [valid_dataset[int(j)]['target'] for j in perm]\n",
    "utils.display_image_grid(\n",
    "    images_array_lst=valid_images_array_lst,\n",
    "    true_labels=valid_images_label_lst\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transfer Learning fo Computer Vision\n",
    "\n",
    "Quoting these notes from [cs231n](https://cs231n.github.io/transfer-learning/),\n",
    "\n",
    "In practice, very few people train an entire Convolutional Network from scratch (with random initialization),\n",
    "because it is relatively rare to have a dataset of sufficient size.\n",
    "Instead, it is common to pretrain a ConvNet on a very large dataset\n",
    "(e.g. ImageNet, which contains 1.2 million images with 1000 categories),\n",
    "and then use the ConvNet either as an initialization, or a fixed feature extractor for the task of interest."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeafDiseaseClassifier(Model):\n",
    "    def __init__(self, params: dict,):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        # default: Finetuning the ConvNet\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=params[\"pretrained\"])\n",
    "\n",
    "        # # As fixed feature extractor\n",
    "        # for param in self.resnet18.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=params[\"output_size\"], bias=True)\n",
    "\n",
    "    def config_optimizer(self, *args, **kwargs):\n",
    "        opt = optim.Adam(self.parameters(), lr=self.params[\"learning_rate\"])\n",
    "        return opt\n",
    "\n",
    "    # TODO: config lr_scheduler\n",
    "    # def config_scheduler(self, *args, **kwargs):\n",
    "    #     assert self.optimizer is not None, \"Please set up optimizer first\"\n",
    "    #     sch = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=30, verbose=False)\n",
    "    #     return sch\n",
    "\n",
    "    def config_criterion(self, *args, **kwargs):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "\n",
    "    def loss_fn(self, outputs, targets=None):\n",
    "        \"\"\" calculate loss \"\"\"\n",
    "        if targets is None or self.criterion is None:\n",
    "            print(\"Targets is None or Criterion is None\")\n",
    "            return None\n",
    "        return self.criterion(outputs, targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out: torch.FloatTensor = self.resnet18(x)\n",
    "        return out\n",
    "\n",
    "    def monitor_metrics(self, outputs, targets=None) -> dict:\n",
    "        predictions: np.ndarray = ptu.to_numpy(torch.argmax(outputs, dim=1))\n",
    "        targets: np.ndarray = ptu.to_numpy(targets)\n",
    "        accuracy = metrics.accuracy_score(targets, predictions)\n",
    "        val_metrics = {\n",
    "            \"acc\": accuracy,\n",
    "        }\n",
    "        return val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define training parameter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: change param\n",
    "print(df.label.unique().shape[0])\n",
    "# training param\n",
    "params = {\n",
    "    \"output_size\":5,\n",
    "    \"max_epochs\": 3,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"valid_batch_size\": 16*2,\n",
    "    'fp16': True,\n",
    "    'seed': 42,\n",
    "    'no_gpu': False,\n",
    "    'which_gpu': 0,\n",
    "    'num_workers': -1,\n",
    "    'learning_rate': 3e-4,\n",
    "    'pretrained': True,\n",
    "    'img_channel': 3,\n",
    "    'img_height': 256,\n",
    "    'img_width': 256,\n",
    "    'save_model': True,\n",
    "\n",
    "}\n",
    "assert params[\"output_size\"] == df.label.unique().shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build NN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create ResNet50\n",
    "resnet18_model:nn.Module = LeafDiseaseClassifier(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if NN build successfully\n",
    "img = train_dataset[0][\"image\"]\n",
    "target = train_dataset[0][\"target\"]\n",
    "img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build success\n",
    "resnet18_model(img.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start training loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clear gpu cache to release memory\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init GPU if available\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# init Trainer\n",
    "resnet18_model.init_trainer(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "# metrics are store in history: dict\n",
    "history = resnet18_model.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=params[\"train_batch_size\"],\n",
    "    valid_dataset=valid_dataset,\n",
    "    valid_batch_size=params[\"valid_batch_size\"],\n",
    "    max_epochs=params[\"max_epochs\"],\n",
    "    device=device,\n",
    "    train_sampler=None,  #ImbalancedDatasetSampler(train_dataset),\n",
    "    valid_sampler=None,  #ImbalancedDatasetSampler(valid_dataset),\n",
    "    num_workers=params[\"num_workers\"], use_fp16=params['fp16'],\n",
    "    save_best=params['save_model'],\n",
    "    better_than=0.8\n",
    "                    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses = history['train_loss']\n",
    "val_losses = history['val_loss']\n",
    "\n",
    "plt.plot(train_losses, '-x')\n",
    "plt.plot(val_losses, '-o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss vs. No. of Epochs')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_acc = np.array(history['train_acc'])\n",
    "avg_train_acc = np.vstack(train_acc).mean(axis=1)\n",
    "\n",
    "\n",
    "val_acc = np.array(history['val_acc'])\n",
    "avg_val_acc = np.vstack(val_acc).mean(axis=1)\n",
    "\n",
    "plt.plot(avg_train_acc, '-x')\n",
    "plt.plot(avg_val_acc, '-o')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.title('Accuracy vs. No. of Epochs')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO: add confusion_mtx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO: finish optuna automate hyperparam tuning [example](https://github.com/optuna/optuna/blob/master/examples/pytorch/pytorch_simple.py)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def define_model(trial: optuna.Trial):\n",
    "    ...\n",
    "def objective(trial: optuna.Trial):\n",
    "    # Generate the model\n",
    "    model=resnet18_model.to(device)\n",
    "\n",
    "    # Generate the optimizers\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader, valid_loader = ...\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "study = optuna.create_study(direction=)\n",
    "study.optimize(objective(), n_trials=..., timeout=600)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clear gpu cache to release memory\n",
    "torch.cuda.empty_cache()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: AutoAlbument\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}